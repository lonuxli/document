# å†…å­˜ç®¡ç†ä¹‹slab shrinkeræ¡†æž¶

slab shrinkerç”¨æˆ·å›žæ”¶å°å—çš„slabç¼“å­˜ï¼Œä¸»è¦å¦‚dentryå’Œinodeç¼“å­˜

åŸºäºŽ4.9.37å†…æ ¸åˆ†æž

**ä¸€ã€æ•°æ®ç»“æž„**

```
struct shrinker {
Â Â Â Â Â Â Â Â unsigned long (*count_objects)(struct shrinker *,Â Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrink_control *sc); //return the number of freeable items in the cache
Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â  Â  //è¿”å›žå¯å›žæ”¶çš„objé¡¹
Â Â Â Â Â Â Â Â unsigned long (*scan_objects)(struct shrinker *,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrink_control *sc);Â  // scan the cache and attempt to free items from the cache
Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â  Â  //è¿”å›žæ‰«æè¿‡ç¨‹ä¸­çœŸæ­£æ˜¯å¦çš„objæ•°é‡

Â Â Â Â Â Â Â Â int seeks;Â Â Â Â Â Â /* seeks to recreate an obj */
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // ã€ŠULKã€‹-informally, it is a parameter that indicates how much it costs to re-create one item of the cache once it is removed
Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â  Â  //Â å®ƒæ˜¯ä¸€ä¸ªå‚æ•°ï¼ŒæŒ‡ç¤ºä¸€æ—¦åˆ é™¤ç¼“å­˜ï¼Œé‡æ–°åˆ›å»ºç¼“å­˜çš„ä¸€é¡¹ä¼šèŠ±è´¹å¤šå°‘è´¹ç”¨ï¼Œç”¨äºŽè°ƒæ•´æ‰«ææ¬¡æ•°

Â Â Â Â Â Â Â Â long batch;Â Â Â Â Â /* reclaim batch size, 0 = default */ //å›žæ”¶æ‰¹æ¬¡å¤§å°,ä¸€æ¬¡å›žæ”¶çš„å¤§å°
Â Â Â Â Â Â Â Â unsigned long flags;

Â Â Â Â Â Â Â Â /* These are for internal use */
Â Â Â Â Â Â Â Â struct list_head list; //é“¾æŽ¥ä¸²èµ·ä¸åŒçš„shrinker
Â Â Â Â Â Â Â Â /* objs pending delete, per node */
Â Â Â Â Â Â Â Â atomic_long_t *nr_deferred;Â  //æ¯ä¸ªèŠ‚ç‚¹å¾…åˆ é™¤çš„objsï¼Œåº”è¯¥æ˜¯ä½œä¸ºä¸€ä¸ªç¼“å­˜ï¼Œåœ¨æŸä¸€nodeä¸­ä¸Šä¸€æ¬¡æœªå®Œæˆçš„æ‰«ææ¬¡æ•°ï¼Œç¼“å­˜ä½åœ¨ä¸‹ä¸€æ¬¡æ‰«æç´¯åŠ 
};
#define DEFAULT_SEEKS 2 /* A good number if you don't know better. */

struct shrink_control {
Â Â Â Â Â Â Â Â gfp_t gfp_mask;

Â Â Â Â Â Â Â Â /*
Â Â Â Â Â Â Â Â Â * How many objects scan_objects should scan and try to reclaim.
Â Â Â Â Â Â Â Â Â * This is reset before every call, so it is safe for callees
Â Â Â Â Â Â Â Â Â * to modify.
Â Â Â Â Â Â Â Â Â */
Â Â Â Â Â Â Â Â unsigned long nr_to_scan;Â  //æ‰«æçš„æ•°é‡

Â Â Â Â Â Â Â Â /* current node being shrunk (for NUMA aware shrinkers) */
Â Â Â Â Â Â Â Â int nid;Â  //æŒ‡å®šnumaÂ node id

Â Â Â Â Â Â Â Â /* current memcg being shrunk (for memcg aware shrinkers) */
Â Â Â Â Â Â Â Â struct mem_cgroup *memcg;Â  //æŒ‡å®šmem cgroup
};
```

```
/*
* Add a shrinker callback to be called from the vm.
*/
int register_shrinker(struct shrinker *shrinker)
{Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â size_t size = sizeof(*shrinker->nr_deferred);
Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â if (shrinker->flags & SHRINKER_NUMA_AWARE)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â size *= nr_node_ids;
Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â shrinker->nr_deferred = kzalloc(size, GFP_KERNEL);
Â Â Â Â Â Â Â Â if (!shrinker->nr_deferred)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â return -ENOMEM;
Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â down_write(&shrinker_rwsem);
Â Â Â Â Â Â Â Â list_add_tail(&shrinker->list, &shrinker_list);
Â Â Â Â Â Â Â Â up_write(&shrinker_rwsem);
Â Â Â Â Â Â Â Â return 0;
}
EXPORT_SYMBOL(register_shrinker);

/*
* Remove one
*/
void unregister_shrinker(struct shrinker *shrinker)
{
Â Â Â Â Â Â Â Â if (!shrinker->nr_deferred)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â return;
Â Â Â Â Â Â Â Â down_write(&shrinker_rwsem);
Â Â Â Â Â Â Â Â list_del(&shrinker->list);
Â Â Â Â Â Â Â Â up_write(&shrinker_rwsem);
Â Â Â Â Â Â Â Â kfree(shrinker->nr_deferred);
Â Â Â Â Â Â Â Â shrinker->nr_deferred = NULL;
}
```

**äºŒã€slabå›žæ”¶**

```
static unsigned long shrink_slab(gfp_t gfp_mask, int nid,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct mem_cgroup *memcg,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â unsigned long nr_scanned,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â unsigned long nr_eligible)
{

Â Â  Â list_for_each_entry(shrinker, &shrinker_list, list) {
Â Â  Â Â Â  Â freed += do_shrink_slab(&sc, shrinker, nr_scanned, nr_eligible); //å¾ªçŽ¯éåŽ†æ‰€æœ‰æ³¨å†Œçš„shrinkerå›žæ”¶
Â Â  Â }
}

static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrinker *shrinker,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â unsigned long nr_scanned,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â unsigned long nr_eligible)
{Â 
1ã€è®¡ç®—scanå‚æ•°ï¼Œä¸ºä½•scanè®¡ç®—å¦‚æ­¤å¤æ‚ ï¼Ÿ
Â Â  Â Â Â  Â freeable = shrinker->count_objects(shrinker, shrinkctl);
Â Â  Â Â Â  Â nr = atomic_long_xchg(&shrinker->nr_deferred[nid], 0);

Â  Â  Â  Â  total_scan = nr;
Â Â Â Â Â Â Â Â delta = (4 * nr_scanned) / shrinker->seeks;
Â Â Â Â Â Â Â Â delta *= freeable;
Â Â Â Â Â Â Â Â do_div(delta, nr_eligible + 1);
Â Â Â Â Â Â Â Â total_scan += delta;

//delta =Â (4 * nr_scanned * freeable) / (shrinker->seeks *Â nr_eligible)
//nr_scanned /Â nr_eligibleÂ å½¢æˆä¸€ä¸ªæ¯”ä¾‹ä½œä¸ºå…¥å‚ï¼Œè°ƒæ•´æ‰«æçš„æ•°é‡

2ã€ä¼ å…¥scanå…¥å‚è¿›è¡Œå›žæ”¶
Â Â Â Â Â Â Â Â while (total_scan >= batch_size ||
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â total_scan >= freeable) {
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â unsigned long ret;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â unsigned long nr_to_scan = min(batch_size, total_scan);

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â shrinkctl->nr_to_scan = nr_to_scan;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ret = shrinker->scan_objects(shrinker, shrinkctl);
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if (ret == SHRINK_STOP)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â freed += ret;

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â count_vm_events(SLABS_SCANNED, nr_to_scan);
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â total_scan -= nr_to_scan;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â scanned += nr_to_scan;

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â cond_resched();
Â Â Â Â Â Â Â Â }
}
```

**ä¸‰ã€é€šç”¨æ–‡ä»¶ç³»ç»Ÿslabå›žæ”¶æ¡†æž¶**

```
//æ–‡ä»¶ç³»ç»Ÿsuperåˆ†é…æ—¶æ³¨å†Œéƒ½ä¼šæ³¨å†Œä¸€ä¸ªé€šç”¨çš„denry/inode shrinker
static struct super_block *alloc_super(struct file_system_type *type, int flags,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct user_namespace *user_ns)
{Â 
Â Â Â Â Â Â Â s->s_shrink.seeks = DEFAULT_SEEKS;
Â Â Â Â Â Â Â Â s->s_shrink.scan_objects = super_cache_scan;
Â Â Â Â Â Â Â Â s->s_shrink.count_objects = super_cache_count;
Â Â Â Â Â Â Â Â s->s_shrink.batch = 1024;
Â Â Â Â Â Â Â Â s->s_shrink.flags = SHRINKER_NUMA_AWARE | SHRINKER_MEMCG_AWARE;
}

static unsigned long super_cache_count(struct shrinker *shrink,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrink_control *sc)
{
Â Â Â Â Â Â Â Â struct super_block *sb;
Â Â Â Â Â Â Â Â longÂ Â Â Â total_objects = 0;

Â Â Â Â Â Â Â Â sb = container_of(shrink, struct super_block, s_shrink);

Â Â Â Â Â Â Â Â if (sb->s_op && sb->s_op->nr_cached_objects)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â total_objects = sb->s_op->nr_cached_objects(sb, sc); //ç»Ÿè®¡å…¶ä»–slabÂ cache

Â Â Â Â Â Â Â Â total_objects += list_lru_shrink_count(&sb->s_dentry_lru, sc); //ç»Ÿè®¡è¯¥æ–‡ä»¶ç³»ç»ŸdentryÂ slabç¼“å­˜æ•°
Â Â Â Â Â Â Â Â total_objects += list_lru_shrink_count(&sb->s_inode_lru, sc);Â Â //ç»Ÿè®¡è¯¥æ–‡ä»¶ç³»ç»Ÿinode slabç¼“å­˜æ•°

Â Â Â Â Â Â Â Â total_objects = vfs_pressure_ratio(total_objects);
Â Â Â Â Â Â Â Â return total_objects;
}

static unsigned long super_cache_scan(struct shrinker *shrink,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrink_control *sc)
{
Â Â Â Â Â Â Â Â struct super_block *sb;
Â Â Â Â Â Â Â Â longÂ Â Â Â fs_objects = 0;
Â Â Â Â Â Â Â Â longÂ Â Â Â total_objects;
Â Â Â Â Â Â Â Â longÂ Â Â Â freed = 0;
Â Â Â Â Â Â Â Â longÂ Â Â Â dentries;
Â Â Â Â Â Â Â Â longÂ Â Â Â inodes;

Â Â Â Â Â Â Â Â sb = container_of(shrink, struct super_block, s_shrink);

Â Â Â Â Â Â Â Â /*
Â Â Â Â Â Â Â Â Â * Deadlock avoidance.Â Â We may hold various FS locks, and we don't want
Â Â Â Â Â Â Â Â Â * to recurse into the FS that called us in clear_inode() and friends..
Â Â Â Â Â Â Â Â Â */
Â Â Â Â Â Â Â Â if (!(sc->gfp_mask & __GFP_FS))
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â return SHRINK_STOP;

Â Â Â Â Â Â Â Â if (!trylock_super(sb))
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â return SHRINK_STOP;

Â Â Â Â Â Â Â Â if (sb->s_op->nr_cached_objects)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â fs_objects = sb->s_op->nr_cached_objects(sb, sc);

Â Â Â Â Â Â Â Â inodes = list_lru_shrink_count(&sb->s_inode_lru, sc);
Â Â Â Â Â Â Â Â dentries = list_lru_shrink_count(&sb->s_dentry_lru, sc);
Â Â Â Â Â Â Â Â total_objects = dentries + inodes + fs_objects + 1;
Â Â Â Â Â Â Â Â if (!total_objects)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â total_objects = 1;

Â Â Â Â Â Â Â Â /* proportion the scan between the caches */
Â Â Â Â Â Â Â Â dentries = mult_frac(sc->nr_to_scan, dentries, total_objects);
Â Â Â Â Â Â Â Â inodes = mult_frac(sc->nr_to_scan, inodes, total_objects);
Â Â Â Â Â Â Â Â fs_objects = mult_frac(sc->nr_to_scan, fs_objects, total_objects);

Â Â Â Â Â Â Â Â /*
Â Â Â Â Â Â Â Â Â * prune the dcache first as the icache is pinned by it, then
Â Â Â Â Â Â Â Â Â * prune the icache, followed by the filesystem specific caches
Â Â Â Â Â Â Â Â Â *
Â Â Â Â Â Â Â Â Â * Ensure that we always scan at least one object - memcg kmem
Â Â Â Â Â Â Â Â Â * accounting uses this to fully empty the caches.
Â Â Â Â Â Â Â Â Â */
Â Â Â Â Â Â Â Â sc->nr_to_scan = dentries + 1;
Â Â Â Â Â Â Â Â freed = prune_dcache_sb(sb, sc);
Â Â Â Â Â Â Â Â sc->nr_to_scan = inodes + 1;
Â Â Â Â Â Â Â Â freed += prune_icache_sb(sb, sc);

Â Â Â Â Â Â Â Â if (fs_objects) {
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â sc->nr_to_scan = fs_objects + 1;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â freed += sb->s_op->free_cached_objects(sb, sc);
Â Â Â Â Â Â Â Â }

Â Â Â Â Â Â Â Â up_read(&sb->s_umount);
Â Â Â Â Â Â Â Â return freed;
}
```

**å››ã€æ–‡ä»¶ç³»ç»Ÿä¸­å…¶ä»–slab cacheå›žæ”¶æ¡†æž¶**

```
struct super_operations {
Â Â Â Â Â Â Â Â long (*nr_cached_objects)(struct super_block *,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrink_control *);
Â Â Â Â Â Â Â Â long (*free_cached_objects)(struct super_block *,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct shrink_control *);
}
æ–‡ä»¶ç³»ç»Ÿå®žçŽ°å…·ä½“çš„nr_cached_objectså’Œfree_cached_objectsï¼Œè¯¥æ¡†æž¶ç”¨äºŽå›žæ”¶é™¤dentryå’Œinodeä»¥å¤–çš„æ–‡ä»¶ç³»ç»Ÿç‰¹æœ‰çš„slabç¼“å­˜ã€‚
ä¾‹å¦‚ï¼š

static const struct super_operations xfs_super_operations = {
Â Â Â Â Â Â Â Â .nr_cached_objectsÂ Â Â Â Â Â = xfs_fs_nr_cached_objects,
Â Â Â Â Â Â Â Â .free_cached_objectsÂ Â Â Â = xfs_fs_free_cached_objects,
};

static const struct super_operations shmem_ops = {
#ifdef CONFIG_TRANSPARENT_HUGE_PAGECACHE
Â Â Â Â Â Â Â Â .nr_cached_objectsÂ Â Â Â Â Â = shmem_unused_huge_count,
Â Â Â Â Â Â Â Â .free_cached_objectsÂ Â Â Â = shmem_unused_huge_scan,
#endif
};
```

**äº”ã€vfs\_cache\_pressureÂ Â** 

æŽ§åˆ¶æ–‡ä»¶ç³»ç»Ÿä¸­cacheå›žæ”¶çš„åŽ‹åŠ›

æ–‡ä»¶ï¼š/proc/sys/vm/vfs\_cache\_pressure

ä¸»è¦åº”ç”¨è§å‡½æ•°super\_cache\_count\(\)ï¼Œè¯¥å‚æ•°æŽ§åˆ¶æ‰«ææ‰«æç™¾åˆ†æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯100ã€‚

```
total_objects = vfs_pressure_ratio(total_objects);

static inline unsigned long vfs_pressure_ratio(unsigned long val)
{
Â Â Â Â Â Â Â Â return mult_frac(val, sysctl_vfs_cache_pressure, 100);
}
```

**å…­ã€æ•´ä½“æ¡†æž¶**

æ€»å…±æœ‰ä¸‰ä¸ªå…¥å£è¿›è¡Œslabå›žæ”¶ï¼Œå…¶ä¸­ç›´æŽ¥å›žæ”¶å’Œå‘¨æœŸå›žæ”¶çš„å…¥å‚æ˜¯ä¸å›ºå®šçš„ï¼Œä¸»åŠ¨å›žæ”¶çš„å…¥å‚å›ºå®š

![85aaf0ea0bf1214a8acdefa7207f1ab3.png](image/85aaf0ea0bf1214a8acdefa7207f1ab3.png)

**ä¸ƒã€4.15å†…æ ¸ç‰ˆæœ¬ä¼˜åŒ–**

commit 9092c71bb724dba2ecba849eae69e5c9d39bd3d2

```
å°†æ‰«æå…¥å‚æ”¹ä¸º priorityï¼Œæ ¹æ®priorityè®¡ç®—å‡ºæ‰«æçš„æ•°é‡ï¼šscan_objects = nr_objects >> sc->priority
static unsigned long shrink_slab(gfp_t gfp_mask, int nid,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â struct mem_cgroup *memcg,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â int priority)
{
Â Â  Â Â Â  Â Â Â  Â Â Â  Â delta = freeable >> priority;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â delta *= 4;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â do_div(delta, shrinker->seeks);
}
```
